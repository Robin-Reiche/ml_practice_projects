{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Daten importieren\n","*Datenquelle: [https://www.kaggle.com/datasets/amritpal333/hepatitis-c-virus-blood-biomarkers/data](https://www.kaggle.com/datasets/amritpal333/hepatitis-c-virus-blood-biomarkers/data)*"],"metadata":{"id":"tPQg-Ot21wql"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Schritt 1: Lese die entsprechende Datei ein, speichere die Daten in der Variable 'df' ab und gib sie anschließend aus.\n","df = ...\n","df"],"metadata":{"id":"eXEM5f0510Fn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 2: Analysiere die Daten mithilfe von '.describe()'\n","..."],"metadata":{"id":"j3iJBVjhgY_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 3: Führe diese Zelle aus, um für jede Spalte den Prozentsatz fehlender Werte anzuzeigen.\n","df.isnull().sum() / len(df)"],"metadata":{"id":"KLhkDMYB9sT1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Daten aufteilen"],"metadata":{"id":"qOz8y0Uc4mOT"}},{"cell_type":"code","source":["# Schritt 4: Weise die entsprechenden Features der Eingabevariable X und das zugehörige Ziel der Zielvariable y zu.\n","# Tipp: Verwende '.copy()' und '.pop()'.\n","X = ...\n","y = ..."],"metadata":{"id":"T6TmEGmm4pWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"id":"5D9uuLs0uyJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"VfGTeq5OEDJj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Schritt 5: Teile die Daten in Trainings- und Testdaten auf. Die Testdaten sollten 20% des Gesamtdatensatzes ausmachen und prozentual dieselbe Anzahl von Klassen wie die Trainingsdaten enthalten.\n","X_train, X_test, y_train, y_test = ..."],"metadata":{"id":"u2Ka8yDjviYf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modell-Pipeline erstellen"],"metadata":{"id":"B9oNmlTdUJhB"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","# Schritt 6: Führe diese Zelle aus, um die Funktion 'create_neural_network' zu definieren.\n","def create_neural_network(hidden_layers, hidden_layer_neurons, input_shape, hidden_layer_activation,\n","                 output_neurons, output_activation, optimizer, loss):\n","    model = tf.keras.Sequential()\n","    model.add(layers.Dense(units=hidden_layer_neurons, activation=hidden_layer_activation, input_shape=input_shape))\n","\n","    for _ in range(hidden_layers - 1):\n","        model.add(layers.Dense(units=hidden_layer_neurons, activation=hidden_layer_activation))\n","\n","    model.add(layers.Dense(units=output_neurons, activation=output_activation))\n","    model.compile(optimizer=optimizer, loss=loss)\n","    return model\n"],"metadata":{"id":"9kY8IcGi3eNA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","!pip install scikeras==0.12.0\n","from scikeras.wrappers import KerasClassifier\n","\n","# Schritt 7: Erstelle eine Instanz von 'StandardScaler' und vervollständige die Pipeline.\n","standard_scaler = ...\n","model = KerasClassifier(model=create_neural_network)\n","\n","pipeline = Pipeline(steps=[\n","    (\"scaler\", ...),\n","    (\"classifier\", ...)\n","])"],"metadata":{"id":"WM7iSqS0VTDA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hyperparameteroptimierung"],"metadata":{"id":"vwzaBCuT-99D"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","# Schritt 8: Erstelle jeweils eine Liste mit verschiedenen Werten für 'hidden_layers' und 'hidden_layer_neurons'.\n","param_grid = {\n","    \"classifier__model__hidden_layers\": [..., ...],\n","    \"classifier__model__hidden_layer_neurons\": [..., ...],\n","    \"classifier__model__input_shape\": [[13]],\n","    \"classifier__model__hidden_layer_activation\": [\"relu\"],\n","    \"classifier__model__output_neurons\": [1],\n","    \"classifier__model__output_activation\": [\"sigmoid\"],\n","    \"classifier__model__optimizer\": [\"adam\"],\n","    \"classifier__model__loss\": [\"binary_crossentropy\"],\n","}\n","\n","# Schritt 9: Setze bei GridSearchCV die Anzahl an Folds auf 4 und scoring auf \"accuracy\".\n","grid_search = GridSearchCV(pipeline, param_grid, cv=..., scoring=...)\n","grid_search.fit(X_train, y_train, classifier__batch_size=512, classifier__epochs=50)\n","\n","print(\"Best Accuracy: \", grid_search.best_score_)\n","print(\"Best Parameters: \", grid_search.best_params_)"],"metadata":{"id":"9wrLFRNS-xDr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Early Stopping, um *epochs* besser zu bestimmen"],"metadata":{"id":"RrTK2r4Vq8lk"}},{"cell_type":"code","source":["# Schritt 10: Erstelle ein Modell basierend auf den besten Werten für 'hidden_layers' und 'hidden_layer_neurons', die du im letzten Schritt gefunden hast.\n","early_stopping_model = create_neural_network(hidden_layers=..., hidden_layer_neurons=..., input_shape=[13], hidden_layer_activation=\"relu\",\n","                 output_neurons=1, output_activation=\"sigmoid\", optimizer=\"adam\", loss=\"binary_crossentropy\")\n","\n","early_stopping_pipeline = Pipeline(steps=[\n","    (\"scaler\", standard_scaler),\n","    (\"model\", early_stopping_model)\n","])"],"metadata":{"id":"YLeIfqygaE_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Schritt 11: Teile die Trainingsdaten wieder in neue Trainings- und Validierungsdaten auf, und führe diese Zelle aus, um das Verfahren \"Early Stopping\" durchzuführen.\n","X_train_new, X_valid, y_train_new, y_valid = train_test_split(..., ..., test_size=0.2, random_state=0)\n","early_stopping = EarlyStopping(min_delta=0.0001, patience=50)\n","\n","standard_scaler.fit(X_train_new)\n","\n","early_stopping_pipeline.fit(\n","    X_train_new, y_train_new,\n","    model__validation_data=(standard_scaler.transform(X_valid), y_valid),\n","    model__batch_size=512,\n","    model__epochs=50000,\n","    model__callbacks=[early_stopping]\n",")"],"metadata":{"id":"I1_tby-etfc_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Besten Wert für *epochs* ausgeben:"],"metadata":{"id":"PpqJJlSwsSJQ"}},{"cell_type":"code","source":["# Schritt 12: Bestimme mithilfe von 'early_stopping.best_epoch' die beste Anzahl an Epochen.\n","\n","best_number_of_epochs = ...\n","best_number_of_epochs"],"metadata":{"id":"gn9QHwd0riNy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ergebnisse visualisieren"],"metadata":{"id":"xFtEaynctfy4"}},{"cell_type":"code","source":["import seaborn as sns\n","\n","history = early_stopping_pipeline.named_steps[\"model\"].history.history\n","\n","# Schritt 13: Transformiere 'history' in ein DataFrame und visualisiere diese Ergebnisse mithilfe eines Lineplots.\n","history_df = pd.DataFrame(...)\n","sns.lineplot(...)"],"metadata":{"id":"3i_QsisSVTAm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Finales neuronales Netz"],"metadata":{"id":"rTjdSOESwLLL"}},{"cell_type":"code","source":["# Schritt 14: Nutze die gleichen Parameter wie in Schritt 10, um ein Modell zu erstellen, das diesmal auf den vollständigen Trainingsdaten trainiert wird.\n","final_model = create_neural_network(hidden_layers=..., hidden_layer_neurons=..., input_shape=[13], hidden_layer_activation=\"relu\",\n","                 output_neurons=1, output_activation=\"sigmoid\", optimizer=\"adam\", loss=\"binary_crossentropy\")\n","\n","final_pipeline = Pipeline(steps=[\n","    (\"scaler\", standard_scaler),\n","    (\"model\", final_model)\n","])\n","\n","# Schritt 15: Setze die Anzahl an Epochen entsprechend und führe diese Zelle aus, um das finale Modell zu trainieren.\n","final_pipeline.fit(X_train, y_train, model__batch_size=512, model__epochs=...)"],"metadata":{"id":"7TClQGN5DO0L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Finales Ergebnis (Accuracy)"],"metadata":{"id":"vg7dyPP1yEIX"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","y_predict_final = final_pipeline.predict(X_test) >= 0.5\n","\n","#Schritt 16: Berechne die finale Accuracy basierend auf den Testdaten.\n","final_accuracy = accuracy_score(..., ...)\n","\n","print(\"Final Accuracy:\", final_accuracy)"],"metadata":{"id":"sr3vC8UViunC"},"execution_count":null,"outputs":[]}]}