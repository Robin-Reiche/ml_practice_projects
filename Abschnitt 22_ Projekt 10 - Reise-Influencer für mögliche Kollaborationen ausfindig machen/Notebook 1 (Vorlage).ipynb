{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Daten importieren"],"metadata":{"id":"tPQg-Ot21wql"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Schritt 1: Lese die entsprechende Datei ein, speichere die Daten in der Variable 'df' ab und gib sie anschließend aus.\n","df = ...\n","df"],"metadata":{"id":"eXEM5f0510Fn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 2: Analysiere die Daten mithilfe von '.describe()'\n","..."],"metadata":{"id":"yYCkYgQJv6YC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Daten visualisieren"],"metadata":{"id":"e4Fnwfw6sa88"}},{"cell_type":"code","source":["import seaborn as sns\n","\n","# Schritt 3: Führe diese Zelle aus, um die Daten zu visualisieren und festzustellen, welche Kernelfunktion du später benötigen wirst.\n","sns.scatterplot(x=df[\"Years of Travel Experience\"], y=df[\"Average Annual Travel Expense (USD)\"], hue=df[\"Owns a Travel Blog\"])"],"metadata":{"id":"oLE14SEdsdi8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Daten aufteilen"],"metadata":{"id":"qOz8y0Uc4mOT"}},{"cell_type":"code","source":["# Schritt 4: Weise die entsprechenden Features der Eingabevariable X und das zugehörige Ziel der Zielvariable y zu.\n","# Tipp: Verwende '.copy()' und '.pop()'.\n","X = ...\n","y = ..."],"metadata":{"id":"jEotjPHuOHzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"id":"5D9uuLs0uyJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"MjR1joQrRKbM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 5: Verwende .value_counts(), um den prozentualen Anteil jeder Klasse in y anzuzeigen.\n","..."],"metadata":{"id":"ay9caf4fQkfU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Schritt 6: Teile die Daten in Trainings- und Testdaten auf. Die Testdaten sollten 20% des Gesamtdatensatzes ausmachen und prozentual dieselbe Anzahl von Klassen wie die Trainingsdaten enthalten.\n","X_train, X_test, y_train, y_test = ..."],"metadata":{"id":"u2Ka8yDjviYf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Daten skalieren"],"metadata":{"id":"B3auim5gwTfr"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# Schritt 7: Erstelle eine Instanz eines StandardScalers und rufe '.fit()' auf X_train auf.\n","scaler = ...\n","scaler.fit(...)\n","\n","X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n","X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"],"metadata":{"id":"TftuAJw2Jsc3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Trainingsdaten visualisieren"],"metadata":{"id":"TDIapxdudBjt"}},{"cell_type":"code","source":["import seaborn as sns\n","\n","# Schritt 8: Führe diese Zelle aus, um die Trainingsdaten zu visualisieren.\n","sns.scatterplot(x=X_train_scaled[\"Years of Travel Experience\"], y=X_train_scaled[\"Average Annual Travel Expense (USD)\"], hue=y_train)"],"metadata":{"id":"tB0FitZyeQLE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Support Vector Classifier - Hyperparameteroptimierung\n"],"metadata":{"id":"X1n1tnDztAUn"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","\n","# Schritt 9: Setze die Kernelfunktion von dem Support-Vector-Classifier entsprechend.\n","model = SVC(kernel=...)\n","\n","# Schritt 10: Erstelle zwei Listen mit verschiedenen Werten für die beiden Hyperparameter C und gamma.\n","param_grid = {\n","    \"C\": [...],\n","    \"gamma\": [...]\n","}\n","\n","# Schritt 11: Setze bei GridSearchCV die Anzahl an Folds auf 4 und scoring auf \"accuracy\".\n","grid_search = GridSearchCV(model, param_grid, cv=..., scoring=...)\n","grid_search.fit(X_train_scaled, y_train)\n","\n","print(\"Best Accuracy: \", grid_search.best_score_)\n","print(\"Best Parameter: \", grid_search.best_params_)"],"metadata":{"id":"FvYmLsYttHLH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 12: Speichere den besten Support-Vector-Classifier in 'final_model' ab mithilfe von '.best_estimator_'\n","final_model = ..."],"metadata":{"id":"uV11H8WuwekQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Support Vector Classifier - Entscheidungsgrenze visualisieren"],"metadata":{"id":"FPsVY1UweKnh"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","\n","# Schritt 13: Führe diese Zelle aus, um die Entscheidungsgrenzen des Modells und die Trainingsdaten zu visualisieren.\n","def plot_decision_boundaries(model, feature_1, feature_2, target):\n","    # Grenzen des Plots basierend auf den Merkmalen definieren\n","    x_min, x_max = feature_1.min() - 0.2, feature_1.max() + 0.2\n","    y_min, y_max = feature_2.min() - 0.2, feature_2.max() + 0.2\n","\n","    # Ein Gitter von Punkten mit einem Abstand von 0.03 zwischen ihnen erstellen\n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.03), np.arange(y_min, y_max, 0.03))\n","\n","    # Vorhersagen für jeden Punkt im Gitter generieren und die Form der Ausgabe anpassen\n","    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n","    Z = Z.reshape(xx.shape)\n","\n","    # Hintergrund des Plots mit den Vorhersagen färben\n","    plt.pcolormesh(xx, yy, Z, cmap=ListedColormap([\"lightblue\", \"lightcoral\"]))\n","\n","    # Scatterplot der tatsächlichen Datenpunkte\n","    sns.scatterplot(x=feature_1, y=feature_2, hue=target)\n","\n","    # Beschriftung der Achsen und Titel\n","    plt.xlabel(feature_1.name)\n","    plt.ylabel(feature_2.name)\n","    plt.title(\"Entscheidungsgrenze\")\n","\n","plot_decision_boundaries(final_model, X_train_scaled[\"Years of Travel Experience\"], X_train_scaled[\"Average Annual Travel Expense (USD)\"], y_train)"],"metadata":{"id":"yVYS01U9zc6o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Finale Accuracy"],"metadata":{"id":"aH86e6bu71Jj"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","# Schritt 14: Generiere die Vorhersagen für 'X_test_scaled' und berechne damit die finale Accuracy basierend auf den Testdaten.\n","y_predict = final_model.predict(...)\n","accuracy = accuracy_score(..., ...)\n","\n","print(\"Final Accuracy:\", accuracy)"],"metadata":{"id":"pL0n6GnjId_E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Confusion Matrix"],"metadata":{"id":"_ABoIWgXZbdr"}},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Schritt 15: Erstelle eine Confusion Matrix basierend auf den Testdaten und den Vorhersagen, um detailliert zu analysieren, welche Fehler das Modell gemacht hat.\n","ConfusionMatrixDisplay.from_predictions(..., ...)"],"metadata":{"id":"CqbShClBjb4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 16: Führe diese Zelle aus, um die Entscheidungsgrenzen des Modells und die Testsdaten zu visualisieren.\n","plot_decision_boundaries(final_model, X_test_scaled[\"Years of Travel Experience\"], X_test_scaled[\"Average Annual Travel Expense (USD)\"], y_test)"],"metadata":{"id":"kPaIZJUr_QWW"},"execution_count":null,"outputs":[]}]}