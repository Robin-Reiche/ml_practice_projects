{"cells":[{"cell_type":"markdown","metadata":{"id":"tPQg-Ot21wql"},"source":["# Daten importieren"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXEM5f0510Fn"},"outputs":[],"source":["import pandas as pd\n","\n","# Schritt 1: Lese die entsprechende Datei ein, speichere die Daten in der Variable 'df' ab und gib sie anschließend aus.\n","df = ...\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3iJBVjhgY_3"},"outputs":[],"source":["# Schritt 2: Analysiere die Daten mithilfe von '.describe()'\n","..."]},{"cell_type":"code","source":["# Schritt 3: Führe diese Zelle aus, um für jede Spalte den Prozentsatz fehlender Werte anzuzeigen.\n","df.isnull().sum() / len(df)"],"metadata":{"id":"_WLo3hmyPvVF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOz8y0Uc4mOT"},"source":["# Daten aufteilen"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jEotjPHuOHzR"},"outputs":[],"source":["# Schritt 4: Weise die entsprechenden Features der Eingabevariable X und das zugehörige Ziel der Zielvariable y zu.\n","# Tipp: Verwende '.copy()' und '.pop()'.\n","X = ...\n","y = ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5D9uuLs0uyJZ"},"outputs":[],"source":["X"]},{"cell_type":"code","source":["y"],"metadata":{"id":"JJkWtCR1-0bZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u2Ka8yDjviYf"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Schritt 5: Unterteile die Daten in Trainings- und Testdaten, wobei die Testdaten 20% der Gesamtdaten ausmachen sollten.\n","X_train, X_test, y_train, y_test = ..."]},{"cell_type":"code","source":["X_train"],"metadata":{"id":"bCDuoxA0-_ig"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Pipelines erstellen"],"metadata":{"id":"Vj7whSC8EPBw"}},{"cell_type":"markdown","source":["### room_length und room_width"],"metadata":{"id":"hHQb2iPw6DFR"}},{"cell_type":"code","source":["from sklearn.impute import SimpleImputer\n","\n","# Schritt 6: Setze die 'strategy' von 'SimpleImputer' entsprechend, um die fehlenden Werte in den Spalten 'room_length (m)' und 'room_width (m)' zu ersetzen.\n","# Tipp: Du hast die Wahl zwischen \"mean\" und \"most_frequent\".\n","num_imputer_1 = SimpleImputer(strategy=\"...\")"],"metadata":{"id":"wDgxbfq_qyAR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.base import BaseEstimator, TransformerMixin\n","\n","# Feature Engineering: Die Zimmerfläche lässt sich durch die Multiplikation von den Spalten 'room_length (m)' und 'room_width (m)' berechnen.\n","# Schritt 7: Führe diese Zelle aus, um den 'ColumnMultiplier' zu definieren, der es ermöglicht eine Zusätzliche Spalte mit den Zimmerflächen zu erzeugen.\n","class ColumnMultiplier(BaseEstimator, TransformerMixin):\n","    def __init__(self, column1_idx, column2_idx):\n","        self.column1_idx = column1_idx\n","        self.column2_idx = column2_idx\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = np.array(X)\n","        new_column = X[:, self.column1_idx] * X[:, self.column2_idx]\n","        X = np.column_stack((X, new_column))\n","        return X"],"metadata":{"id":"RB4aVHCzy0PD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 8: Setze 'column1_idx' auf den Index der Spalte 'room_length (m)' und 'column2_idx' auf den Index der Spalte 'room_width (m)'.\n","column_multiplier = ColumnMultiplier(column1_idx=..., column2_idx=...)"],"metadata":{"id":"bShDmiWwAwYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","\n","# Schritt 9: Vervollständige die Pipeline mithilfe der Instanzen, die du in Schritt 6 und Schritt 8 erstellt hast und führe diese Zelle aus, um die transformierten Features zu sehen.\n","room_dimensions_pipeline = Pipeline(steps=[\n","    (\"imputer\", ...),\n","    (\"multiplier\", ...)\n","])\n","\n","num_columns = [\"room_length (m)\", \"room_width (m)\"]\n","expanded_num_columns = [\"room_length (m)\", \"room_width (m)\", \"room_area (m^2)\"]\n","\n","final_room_dimensions_train = pd.DataFrame(room_dimensions_pipeline.fit_transform(X_train[num_columns]), columns=expanded_num_columns, index=X_train.index)\n","final_room_dimensions_test = pd.DataFrame(room_dimensions_pipeline.transform(X_test[num_columns]), columns=expanded_num_columns, index=X_test.index)\n","\n","final_room_dimensions_train"],"metadata":{"id":"f0XeM7Iq-2nR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### kitchen_size"],"metadata":{"id":"n8qf8L-WFUAH"}},{"cell_type":"code","source":["# Schritt 10: Setze die 'strategy' von 'SimpleImputer' entsprechend, um die fehlenden Einträge in der Spalte 'kitchen_size' zu ersetzen.\n","# Tipp: Du hast die Wahl zwischen \"mean\" und \"most_frequent\".\n","cat_imputer_1 = SimpleImputer(strategy=\"...\")"],"metadata":{"id":"vLWvqrD9Fu3J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import OrdinalEncoder\n","\n","# Schritt 11: Vervollständige die Liste 'custom_order', um die Rangfolge der Einträge in der Spalte 'kitchen_size' zu definieren.\n","custom_order = [\"...\", \"...\", \"...\"]\n","ordinal_encoder = OrdinalEncoder(categories=[custom_order], handle_unknown=\"use_encoded_value\", unknown_value=-1)"],"metadata":{"id":"VJ_rxP17wnOI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 12: Vervollständige die Pipeline mithilfe der Instanzen, die du in Schritt 10 und Schritt 11 erstellt hast und führe diese Zelle aus, um das transformierte Feature zu sehen.\n","kitchen_size_pipeline = Pipeline(steps=[\n","    (\"imputer\", ...),\n","    (\"encoder\", ...)\n","])\n","\n","final_kitchen_size_train = pd.DataFrame(kitchen_size_pipeline.fit_transform(X_train[[\"kitchen_size\"]]), columns=[\"kitchen_size\"], index=X_train.index)\n","final_kitchen_size_test = pd.DataFrame(kitchen_size_pipeline.transform(X_test[[\"kitchen_size\"]]), columns=[\"kitchen_size\"], index=X_test.index)\n","\n","final_kitchen_size_train"],"metadata":{"id":"TBp4BD81yGk6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### renovation"],"metadata":{"id":"bN2tL5irjt_Q"}},{"cell_type":"code","source":["# Schritt 13: Setze die 'strategy' von 'SimpleImputer' entsprechend, um die fehlenden Einträge in der Spalte 'renovation' zu ersetzen.\n","# Tipp: Du hast die Wahl zwischen \"mean\" und \"most_frequent\".\n","cat_imputer_2 = SimpleImputer(strategy=\"...\")"],"metadata":{"id":"5RVj8ki-xvg4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","\n","# Schritt 14: Führe diese Zelle aus, um eine Instanz von einem 'OneHotEncoder' zu erstellen.\n","oh_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)"],"metadata":{"id":"CO_rKER9liWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 15: Vervollständige die Pipeline mithilfe der Instanzen, die du in Schritt 13 und Schritt 14 erstellt hast und führe diese Zelle aus, um das transformierte Feature zu sehen.\n","renovation_pipeline = Pipeline(steps=[\n","    (\"imputer\", ...),\n","    (\"encoder\", ...)\n","])\n","\n","oh_columns = [\"not renovated\", \"renovated\"]\n","\n","final_renovation_train = pd.DataFrame(renovation_pipeline.fit_transform(X_train[[\"renovation\"]]), columns=oh_columns, index=X_train.index)\n","final_renovation_test = pd.DataFrame(renovation_pipeline.transform(X_test[[\"renovation\"]]), columns=oh_columns, index=X_test.index)\n","\n","final_renovation_train"],"metadata":{"id":"AtMNbReUq-Wl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# latitude und longitude"],"metadata":{"id":"d8qhWISrV5rY"}},{"cell_type":"code","source":["import seaborn as sns\n","\n","# Schritt 16: Führe diese Zelle aus, um die Koordinaten zu visualisieren und die Anzahl der Cluster zu bestimmen, die du später für K-Means benötigen wirst.\n","sns.scatterplot(x=X_train[\"latitude\"], y=X_train[\"longitude\"], s=5)"],"metadata":{"id":"RMs04MBHYgB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 17: Setze die 'strategy' von 'SimpleImputer' entsprechend, um die fehlenden Werte in den Spalten 'latitude' und 'longitude' zu ersetzen.\n","# Tipp: Du hast die Wahl zwischen \"mean\" und \"most_frequent\".\n","num_imputer_2 = SimpleImputer(strategy=\"...\")"],"metadata":{"id":"E66Sznb3XfYC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","# Schritt 18: Erstelle eine Instanz von 'StandardScaler', um die Daten vor dem K-Means-Clustering zu skalieren.\n","standard_scaler = ..."],"metadata":{"id":"Oevn1oF4XfVz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.cluster import KMeans\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","class ClusterCreator(BaseEstimator, TransformerMixin):\n","    def __init__(self, n_clusters):\n","        self.n_clusters = n_clusters\n","        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=0)\n","\n","    def fit(self, X, y=None):\n","        self.kmeans.fit(X)\n","        return self\n","\n","    def transform(self, X):\n","        clusters = self.kmeans.predict(X)\n","        return clusters.reshape(-1, 1)\n","\n","# Schritt 19: Nutze deine beobachtung aus Schritt 16, um 'n_clusters' entsprechend zu setzen.\n","cluster_creator = ClusterCreator(n_clusters=...)"],"metadata":{"id":"ZnTUZdqDXfMb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 20: Vervollständige die Pipeline mit den Instanzen, die du in Schritt 17, Schritt 18 und Schritt 19 erstellt hast, und führe diese Zelle aus, um die Cluster auszugeben.\n","coordinates_pipeline = Pipeline(steps=[\n","    (\"imputer\", ...),\n","    (\"scaler\", ...),\n","    (\"clusterer\", ...)\n","])\n","\n","coordinates_columns = [\"latitude\", \"longitude\"]\n","\n","clustered_train_coordinates = pd.DataFrame(coordinates_pipeline.fit_transform(X_train[coordinates_columns]), columns=[\"Cluster\"], index=X_train.index)\n","clustered_test_coordinates = pd.DataFrame(coordinates_pipeline.transform(X_test[coordinates_columns]), columns=[\"Cluster\"], index=X_test.index)\n","\n","clustered_train_coordinates"],"metadata":{"id":"xcVto2b5fO-9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 21: Führe diese Zelle aus, um die erstellten Cluster zu visualisieren.\n","sns.scatterplot(x=X_train[\"latitude\"], y=X_train[\"longitude\"], hue=clustered_train_coordinates[\"Cluster\"], palette=\"Set1\", s=5, legend=False)"],"metadata":{"id":"CpEVnYyFgXm1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ColumnTransformer - Alle Preprocessing Schritte zusammmenführen"],"metadata":{"id":"1eFQV-2_9FUw"}},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","\n","# Schritt 22: Vervollständige den 'ColumnTransformer' mithilfe der Pipelines, die du in Schritt 9, Schritt 12, Schritt 15 und Schritt 20 erstellt hast und führe diese Zelle aus, um die transformierten Features zu sehen.\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"room_dimensions_columns\", ..., [\"room_length (m)\", \"room_width (m)\"]),\n","        (\"kitchen_size_column\", ..., [\"kitchen_size\"]),\n","        (\"renovation_column\", ..., [\"renovation\"]),\n","        (\"coordinates_colums\", ..., [\"latitude\", \"longitude\"])\n","    ])\n","\n","final_columns = [\"room_length (m)\", \"room_width (m)\", \"room_area (m^2)\", \"kitchen_size\", \"not renovated\", \"renovated\", \"Cluster\"]\n","\n","X_train_final = pd.DataFrame(preprocessor.fit_transform(X_train), columns=final_columns, index=X_train.index)\n","X_test_final = pd.DataFrame(preprocessor.transform(X_test), columns=final_columns, index=X_test.index)\n","\n","X_train_final"],"metadata":{"id":"KTy6aRae7svA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modell definieren und finale Pipeline erstellen"],"metadata":{"id":"50fhPNn9FsYf"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","\n","# Schritt 23: Erstelle eine Instanz von 'RandomForestRegressor' und vervollständige die finale Pipeline.\n","model = ...\n","\n","final_pipeline = Pipeline(steps=[\n","    (\"preprocessor\", ...),\n","    (\"model\", ...)\n","])"],"metadata":{"id":"pZxlfEsy7srA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X1n1tnDztAUn"},"source":["# Hyperparameteroptimierung\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FvYmLsYttHLH"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","# Schritt 24: Erstelle jeweils eine Liste mit verschiedenen Werten für 'n_estimators' und 'max_depth'.\n","param_grid = {\n","    \"model__n_estimators\": [...],\n","    \"model__max_depth\": [...]\n","}\n","\n","# Schritt 25: Setze bei GridSearchCV die Anzahl an Folds auf 4 und scoring auf \"neg_mean_absolute_error\".\n","grid_search = GridSearchCV(final_pipeline, param_grid, cv=..., scoring=...)\n","grid_search.fit(X_train, y_train)\n","\n","print(\"Best Mean Absolute Error: \", -grid_search.best_score_)\n","print(\"Best Parameters: \", grid_search.best_params_)"]},{"cell_type":"markdown","metadata":{"id":"M_mvJdPdIcA1"},"source":["# Beste Pipeline und finalen Mean Absolute Error\n","\n"]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","\n","# Schritt 26: Speichere die beste Pipeline in 'best_pipeline' ab mithilfe von '.best_estimator_' und berechne den finalen MAE auf den Testdaten.\n","best_pipeline = ...\n","y_predict = best_pipeline.predict(...)\n","mae = mean_absolute_error(..., ...)\n","\n","print(\"Final MAE:\", mae)"],"metadata":{"id":"B-IxCj7KJKhY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xRIG08VWrE9L"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}