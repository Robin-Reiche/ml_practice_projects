{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Daten importieren\n","*Datenquelle: [https://www.kaggle.com/datasets/vetrirah/customer/data](https://www.kaggle.com/datasets/vetrirah/customer/data)*"],"metadata":{"id":"tPQg-Ot21wql"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Schritt 1: Lese die entsprechende Datei ein, speichere die Daten in der Variable 'df' ab und gib sie anschließend aus.\n","df = ...\n","df"],"metadata":{"id":"eXEM5f0510Fn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 2: Analysiere die Daten mithilfe von '.describe()'.\n","..."],"metadata":{"id":"j3iJBVjhgY_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 3: Nutze .value_counts(), um die Häufigkeit jeder Klasse in der Spalte \"Group\" anzuzeigen.\n","..."],"metadata":{"id":"cRG2pp5tWH7W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","# Schritt 4: Erstelle ein Histogramm, um die Häufigkeit jeder Klasse in der Spalte \"Group\" zu visualisieren.\n","sns.histplot(...)"],"metadata":{"id":"Md8a48JvWqtR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Daten aufteilen"],"metadata":{"id":"qOz8y0Uc4mOT"}},{"cell_type":"code","source":["# Schritt 5: Weise die entsprechenden Features der Eingabevariable X und das zugehörige Ziel der Zielvariable y zu.\n","# Tipp: Verwende '.copy()' und '.pop()'.\n","X = ...\n","y = ..."],"metadata":{"id":"jEotjPHuOHzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"id":"5D9uuLs0uyJZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"0379r7wavOHm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Schritt 6: Teile die Daten in Trainings- und Testdaten auf. Die Testdaten sollten 20% des Gesamtdatensatzes ausmachen und prozentual dieselbe Anzahl von Klassen wie die Trainingsdaten enthalten.\n","X_train, X_test, y_train, y_test = ..."],"metadata":{"id":"u2Ka8yDjviYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 7: Verwende .value_counts(), um den prozentualen Anteil jeder Klasse in y_train anzuzeigen.\n","..."],"metadata":{"id":"2n9WAvK-FvI_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Schritt 8: Verwende .value_counts(), um den prozentualen Anteil jeder Klasse in y_test anzuzeigen.\n","..."],"metadata":{"id":"JTQRgcuGF5Cn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Modell trainieren"],"metadata":{"id":"Rh4hkyISxy8D"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","# Schritt 9: Trainiere das Modell auf den Trainingsdaten.\n","# Anmerkung: Die gewählten Modellparameter 'multi_class' und 'solver' ermöglichen die Durchführung einer Mehrklassen-Klassifikation.\n","model = LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\", random_state=0)\n","model.fit(..., ...)"],"metadata":{"id":"illOuHZnAs8s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Vorhersagen"],"metadata":{"id":"zUutlrHv_Cuu"}},{"cell_type":"code","source":["# Schritt 10: Nutze das trainierte Modell, um Vorhersagen für X_test zu generieren.\n","y_predict = ..."],"metadata":{"id":"fFKh2oDC-9n-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Accuracy"],"metadata":{"id":"M_mvJdPdIcA1"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","\n","# Schritt 11: Berechne die Accuracy basierend auf den Testdaten und den Vorhersagen.\n","accuracy = ...\n","\n","print(\"Final Accuracy:\", accuracy)"],"metadata":{"id":"5D-P4ecEa2Ac"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Confusion Matrix"],"metadata":{"id":"_ABoIWgXZbdr"}},{"cell_type":"code","source":["from sklearn.metrics import ConfusionMatrixDisplay\n","\n","# Schritt 12: Erstelle eine Confusion Matrix basierend auf den Testdaten und den Vorhersagen, um detailliert zu analysieren, welche Fehler das Modell gemacht hat.\n","ConfusionMatrixDisplay.from_predictions(..., ...)"],"metadata":{"id":"_u0TC6m2mQ_9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Precision, Recall und F1-Score (Klassenspezifisch)"],"metadata":{"id":"27ZJK7jnkYhb"}},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","# Schritt 13: Setze den average-Parameter entsprechend, um die Klassenspezifischen Precisions, Recalls und f1-Scores zu berechnen.\n","precisions = precision_score(y_test, y_predict, average=...)\n","recalls = recall_score(y_test, y_predict, average=...)\n","f1 = f1_score(y_test, y_predict, average=...)\n","\n","print(\"Precisions: \", precisions)\n","print(\"Recalls: \", recalls)\n","print(\"F1-Scores: \", f1)"],"metadata":{"id":"0b1o6DpsjvGL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Precision, Recall und F1-Score (Macro-Average)"],"metadata":{"id":"m_47Gnup1DXy"}},{"cell_type":"code","source":["# Schritt 14: Setze den average-Parameter entsprechend, um die Macro-Precision, den Macro-Recall und den Macro-f1-Score zu berechnen.\n","macro_precision = precision_score(y_test, y_predict, average=...)\n","macro_recall = recall_score(y_test, y_predict, average=...)\n","macro_f1 = f1_score(y_test, y_predict, average=...)\n","\n","print(\"Macro-Precision: \", macro_precision)\n","print(\"Macro-Recall: \", macro_recall)\n","print(\"Macro_F1: \", macro_f1)"],"metadata":{"id":"8jDEVB6Ax8b8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Precision, Recall und F1-Score (Weighted-Average)"],"metadata":{"id":"-0sUdciG4T0p"}},{"cell_type":"code","source":["# Schritt 15: Setze den average-Parameter entsprechend, um die Weighted-Precision, den Weighted-Recall und den Weighted-f1-Score zu berechnen.\n","weighted_precision = precision_score(y_test, y_predict, average=...)\n","weighted_recall = recall_score(y_test, y_predict, average=...)\n","weighted_f1 = f1_score(y_test, y_predict, average=...)\n","\n","print(\"Weighted-Precision: \", weighted_precision)\n","print(\"Weighted-Recall: \", weighted_recall)\n","print(\"Weighted_F1: \", weighted_f1)"],"metadata":{"id":"OSqUHSQE4Lbv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Precision, Recall und F1-Score (Micro-Average)"],"metadata":{"id":"rD3Gu_Oa3Dhh"}},{"cell_type":"code","source":["# Schritt 16: Setze den average-Parameter entsprechend, um die Micro-Precision, den Micro-Recall und den Micro-f1-Score zu berechnen.\n","micro_precision = precision_score(y_test, y_predict, average=...)\n","micro_recall = recall_score(y_test, y_predict, average=...)\n","micro_f1 = f1_score(y_test, y_predict, average=...)\n","\n","print(\"Micro-Precision: \", micro_precision)\n","print(\"Micro-Recall: \", micro_recall)\n","print(\"Micro_F1: \", micro_f1)"],"metadata":{"id":"KJj6SXlT2JFI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Classification Report ausgeben"],"metadata":{"id":"7u1biuWk46yV"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","# Schritt 17: Erzeuge einen Klassifikationsbericht basierend auf den Testdaten und den Vorhersagen.\n","report = classification_report(..., ...)\n","print(report)"],"metadata":{"id":"8AAkffl_45qo"},"execution_count":null,"outputs":[]}]}